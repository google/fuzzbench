diff --git a/Makefile b/Makefile
index 3819312..8a9e26e 100644
--- a/Makefile
+++ b/Makefile
@@ -33,7 +33,7 @@ CFLAGS     += -Wall -D_FORTIFY_SOURCE=2 -g -Wno-pointer-sign \
 	      -DBIN_PATH=\"$(BIN_PATH)\"
 
 ifneq "$(filter Linux GNU%,$(shell uname))" ""
-  LDFLAGS  += -ldl
+  LDFLAGS  += -ldl -lm
 endif
 
 ifeq "$(findstring clang, $(shell $(CC) --version 2>/dev/null))" ""
diff --git a/afl-fuzz.c b/afl-fuzz.c
index fc9d210..9deca24 100644
--- a/afl-fuzz.c
+++ b/afl-fuzz.c
@@ -56,6 +56,7 @@
 #include <termios.h>
 #include <dlfcn.h>
 #include <sched.h>
+#include <math.h>
 
 #include <sys/wait.h>
 #include <sys/time.h>
@@ -87,6 +88,9 @@
 #  define EXP_ST static
 #endif /* ^AFL_LIB */
 
+#define HIT_COUNTS_SIZE (1 << 21)
+u32 *hit_counts;
+
 /* Lots of globals, but mostly for the status UI and other things where it
    really makes no sense to haul them around as function parameters. */
 
@@ -1509,6 +1513,9 @@ static void read_testcases(void) {
 
     add_to_queue(fn, st.st_size, passed_det);
 
+    u32 cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
+    hit_counts[cksum % HIT_COUNTS_SIZE] = 1;
+
   }
 
   free(nl); /* not tracked */
@@ -3166,6 +3173,12 @@ static u8 save_if_interesting(char** argv, void* mem, u32 len, u8 fault) {
   s32 fd;
   u8  keeping = 0, res;
 
+  u32 cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
+
+  /* Saturated increment */
+  if (hit_counts[cksum % HIT_COUNTS_SIZE] < 0xFFFFFFFF)
+    hit_counts[cksum % HIT_COUNTS_SIZE]++;
+
   if (fault == crash_mode) {
 
     /* Keep only if there are new bits in the map, add to queue for
@@ -3194,7 +3207,9 @@ static u8 save_if_interesting(char** argv, void* mem, u32 len, u8 fault) {
       queued_with_cov++;
     }
 
-    queue_top->exec_cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
+    queue_top->exec_cksum = cksum;
+
+    hit_counts[cksum % HIT_COUNTS_SIZE] = 1;
 
     /* Try to calibrate inline; this also calls update_bitmap_score() when
        successful. */
@@ -4770,35 +4785,9 @@ static u32 calculate_score(struct queue_entry* q) {
   else if (q->bitmap_size * 2 < avg_bitmap_size) perf_score *= 0.5;
   else if (q->bitmap_size * 1.5 < avg_bitmap_size) perf_score *= 0.75;
 
-  /* Adjust score based on handicap. Handicap is proportional to how late
-     in the game we learned about this path. Latecomers are allowed to run
-     for a bit longer until they catch up with the rest. */
-
-  if (q->handicap >= 4) {
-
-    perf_score *= 4;
-    q->handicap -= 4;
-
-  } else if (q->handicap) {
-
-    perf_score *= 2;
-    q->handicap--;
-
-  }
-
-  /* Final adjustment based on input depth, under the assumption that fuzzing
-     deeper test cases is more likely to reveal stuff that can't be
-     discovered with traditional fuzzers. */
-
-  switch (q->depth) {
-
-    case 0 ... 3:   break;
-    case 4 ... 7:   perf_score *= 2; break;
-    case 8 ... 13:  perf_score *= 3; break;
-    case 14 ... 25: perf_score *= 4; break;
-    default:        perf_score *= 5;
-
-  }
+  double log_hits = log2(hit_counts[q->exec_cksum % HIT_COUNTS_SIZE]);
+  if (q->favored && !q->was_fuzzed) perf_score *= 16;
+  else if (16 - log_hits > 0) perf_score *= 16 - log_hits;
 
   /* Make sure that we don't go over limit. */
 
@@ -5020,30 +5009,11 @@ static u8 fuzz_one(char** argv) {
 
 #else
 
-  if (pending_favored) {
-
-    /* If we have any favored, non-fuzzed new arrivals in the queue,
-       possibly skip to them at the expense of already-fuzzed or non-favored
-       cases. */
-
-    if ((queue_cur->was_fuzzed || !queue_cur->favored) &&
-        UR(100) < SKIP_TO_NEW_PROB) return 1;
-
-  } else if (!dumb_mode && !queue_cur->favored && queued_paths > 10) {
-
-    /* Otherwise, still possibly skip non-favored cases, albeit less often.
-       The odds of skipping stuff are higher for already-fuzzed inputs and
-       lower for never-fuzzed entries. */
-
-    if (queue_cycle > 1 && !queue_cur->was_fuzzed) {
+  /* Prefer late seeds */
+  if (current_entry * (current_entry + 1) / 2 < UR(queued_paths * (queued_paths + 1) / 2)) {
 
-      if (UR(100) < SKIP_NFAV_NEW_PROB) return 1;
-
-    } else {
-
-      if (UR(100) < SKIP_NFAV_OLD_PROB) return 1;
-
-    }
+    /* Exempt favourites and 10 random seeds per cycle */
+    if (10 < UR(queued_paths) && !queue_cur->favored) return 1;
 
   }
 
@@ -6138,7 +6108,7 @@ havoc_stage:
     sprintf(tmp, "splice %u", splice_cycle);
     stage_name  = tmp;
     stage_short = "splice";
-    stage_max   = SPLICE_HAVOC * perf_score / havoc_div / 100;
+    stage_max   = SPLICE_HAVOC / havoc_div;
 
   }
 
@@ -7990,6 +7960,9 @@ int main(int argc, char** argv) {
   setup_signal_handlers();
   check_asan_opts();
 
+  /* Dynamically allocate memory for AFLFast schedules */
+  hit_counts = ck_alloc(HIT_COUNTS_SIZE * sizeof(u32));
+
   if (sync_id) fix_up_sync();
 
   if (!strcmp(in_dir, out_dir))
diff --git a/config.h b/config.h
index 46dd857..8aae20b 100644
--- a/config.h
+++ b/config.h
@@ -94,7 +94,7 @@
 /* Maximum multiplier for the above (should be a power of two, beware
    of 32-bit int overflows): */
 
-#define HAVOC_MAX_MULT      16
+#define HAVOC_MAX_MULT      32
 
 /* Absolute minimum number of havoc cycles (after all adjustments): */
 
